# Ú©Ø¯ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ùˆ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø¯Ù† - Ù†Ø³Ø®Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡
# Ø¨Ø± Ù¾Ø§ÛŒÙ‡ Ù…ÙÙ‡ÙˆÙ… Ø¨Ø³ØªÙ‡ Dart body_analyzerØŒ Ø§Ù…Ø§ Ø¯Ø± Python Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² numpy, pandas, torch Ùˆ matplotlib
# Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§: 
# - Ø­Ø°Ù ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ sklearn (Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÛŒ StandardScaler Ùˆ LabelEncoder Ùˆ train_test_split)
# - Ø§ÙØ²ÙˆØ¯Ù† Ú©Ø±Ø§Ø³-ÙˆØ§Ù„ÛŒØ¯ÛŒØ´Ù†ØŒ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒØŒ Ùˆ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ± (Precision, Recall, F1)
# - Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ: Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ heatmapØŒ Ø¨Ø§Ú©Ø³â€ŒÙ¾Ù„Ø§Øª Ø¨Ø±Ø§ÛŒ ØªÙˆØ²ÛŒØ¹â€ŒÙ‡Ø§ØŒ Ùˆ Ù…Ù†Ø­Ù†ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
# - Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±
# - Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù†Ø³Ø®Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
# - Ù„Ø§Ú¯ÛŒÙ†Ú¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§
# ÙØ±Ø¶: Ù…Ø­ÛŒØ· Python 3.12 Ø¨Ø§ numpy, pandas, torch, matplotlib Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª.
# Ø§Ø¬Ø±Ø§: python body_ml_analyzer_advanced.py

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import matplotlib.pyplot as plt
try:
    import seaborn as sns  # Ø¨Ø±Ø§ÛŒ heatmap (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² matplotlib Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯)
    HAS_SNS = True
except ImportError:
    HAS_SNS = False
from datetime import datetime
import json
import os
import logging

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯ÛŒÙ†Ú¯ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ManualStandardScaler:
    """Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÛŒ StandardScaler"""
    def __init__(self):
        self.mean_ = None
        self.scale_ = None
    
    def fit(self, X):
        self.mean_ = np.mean(X, axis=0)
        self.scale_ = np.std(X, axis=0)
        self.scale_[self.scale_ == 0] = 1  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÙ‚Ø³ÛŒÙ… Ø¨Ø± ØµÙØ±
        return self
    
    def transform(self, X):
        return (X - self.mean_) / self.scale_
    
    def fit_transform(self, X):
        self.fit(X)
        return self.transform(X)

class ManualLabelEncoder:
    """Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÛŒ LabelEncoder"""
    def __init__(self):
        self.classes_ = None
        self.mapping_ = None
    
    def fit(self, y):
        self.classes_ = np.unique(y)
        self.mapping_ = {cls: idx for idx, cls in enumerate(self.classes_)}
        return self
    
    def transform(self, y):
        return np.array([self.mapping_.get(val, -1) for val in y])  # -1 Ø¨Ø±Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡
    
    def fit_transform(self, y):
        self.fit(y)
        return self.transform(y)
    
    def inverse_transform(self, y):
        if self.classes_ is None:
            raise ValueError("Encoder not fitted")
        inverse_mapping = {idx: cls for cls, idx in self.mapping_.items()}
        return np.array([inverse_mapping.get(val, 'Unknown') for val in y])

def manual_train_test_split(X, y, test_size=0.2, random_state=42, stratify=None):
    """Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÛŒ train_test_split Ø¨Ø§ stratify"""
    np.random.seed(random_state)
    indices = np.arange(len(X))
    np.random.shuffle(indices)
    
    if stratify is not None:
        # Stratified split Ø³Ø§Ø¯Ù‡
        unique_classes = np.unique(y)
        train_indices = []
        test_indices = []
        for cls in unique_classes:
            cls_indices = indices[y[indices] == cls]
            n_test = int(len(cls_indices) * test_size)
            test_indices.extend(cls_indices[:n_test])
            train_indices.extend(cls_indices[n_test:])
        test_indices = np.array(test_indices)
        train_indices = np.array(train_indices)
    else:
        n_test = int(len(indices) * test_size)
        test_indices = indices[:n_test]
        train_indices = indices[n_test:]
    
    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]

# ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„ Ø®Ø§Ø±Ø¬ Ø§Ø² Ù…ØªØ¯ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ
class BodyShapeClassifier(nn.Module):
    def __init__(self, input_size, num_classes):
        super().__init__()
        self.fc1 = nn.Linear(input_size, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 64)
        self.fc4 = nn.Linear(64, num_classes)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)
        self.batch_norm1 = nn.BatchNorm1d(256)
        self.batch_norm2 = nn.BatchNorm1d(128)
    
    def forward(self, x):
        x = self.relu(self.batch_norm1(self.fc1(x)))
        x = self.dropout(x)
        x = self.relu(self.batch_norm2(self.fc2(x)))
        x = self.dropout(x)
        x = self.relu(self.fc3(x))
        x = self.dropout(x)
        x = self.fc4(x)
        return x

# Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÛŒ confusion_matrix Ùˆ classification_report
def manual_confusion_matrix(y_true, y_pred, labels=None):
    if labels is None:
        labels = np.unique(np.concatenate((y_true, y_pred)))
    n_classes = len(labels)
    label_to_index = {label: i for i, label in enumerate(labels)}
    cm = np.zeros((n_classes, n_classes), dtype=int)
    for t, p in zip(y_true, y_pred):
        if t in label_to_index and p in label_to_index:
            cm[label_to_index[t], label_to_index[p]] += 1
    return cm

def manual_classification_report(y_true, y_pred, labels=None):
    if labels is None:
        labels = np.unique(np.concatenate((y_true, y_pred)))
    report = {}
    for label in labels:
        tp = np.sum((y_true == label) & (y_pred == label))
        fp = np.sum((y_true != label) & (y_pred == label))
        fn = np.sum((y_true == label) & (y_pred != label))
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        support = np.sum(y_true == label)
        report[label] = {'precision': precision, 'recall': recall, 'f1-score': f1, 'support': support}
    return report

class BodyDataAnalyzer:
    """
    Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø¯Ù†.
    Ø´Ø§Ù…Ù„ ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡ØŒ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ØŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„.
    """
    
    def __init__(self, num_samples=1000):
        self.num_samples = num_samples
        self.df = None
        self.model = None
        self.scaler = ManualStandardScaler()
        self.label_encoder = ManualLabelEncoder()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"Device: {self.device}")
    
    def generate_synthetic_data(self):
        """
        ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ØªÙ‡ Dart.
        Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: bust, underbust, hip, waist, height, weight_kg, bicep, tricep, thigh, calf, body_shape (label)
        """
        logger.info("ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
        np.random.seed(42)  # Ø¨Ø±Ø§ÛŒ ØªÚ©Ø±Ø§Ø±Ù¾Ø°ÛŒØ±ÛŒ
        
        # ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ - Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù…Ø«Ø¨Øª Ø¨ÙˆØ¯Ù† Ø¨Ø§ clip
        age = np.random.randint(18, 65, self.num_samples)
        gender_factor = np.random.choice([0.9, 1.1], self.num_samples)  # ØªÙØ§ÙˆØª Ø¬Ù†Ø³ÛŒØªÛŒ Ø³Ø§Ø¯Ù‡
        
        self.df = pd.DataFrame({
            'bust': np.clip(np.random.normal(36, 4, self.num_samples) * gender_factor, 20, 60),
            'underbust': np.clip(np.random.normal(32, 3, self.num_samples) * gender_factor, 20, 50),
            'hip': np.clip(np.random.normal(38.5, 5, self.num_samples) * gender_factor, 25, 60),
            'waist': np.clip(np.random.normal(28, 4, self.num_samples) * gender_factor, 20, 50),
            'height': np.clip(np.random.normal(65, 4, self.num_samples), 50, 80),
            'weight_kg': np.clip(np.random.normal(60, 10, self.num_samples), 40, 120),
            'bicep': np.clip(np.random.normal(13, 2, self.num_samples), 8, 20),
            'tricep': np.clip(np.random.normal(12.5, 1.5, self.num_samples), 8, 18),
            'thigh': np.clip(np.random.normal(22, 3, self.num_samples), 15, 35),
            'calf': np.clip(np.random.normal(14, 2, self.num_samples), 10, 20),
        })
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ shape Ø¨Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ heuristic Ø³Ø§Ø¯Ù‡ (Ø´Ø¨ÛŒÙ‡ Dart)
        def determine_shape(row):
            bust_diff = abs(row['bust'] - row['waist'])
            hip_diff = abs(row['hip'] - row['waist'])
            if bust_diff < 2 and hip_diff < 2:
                return 'Rectangle'
            elif hip_diff > bust_diff + 2:
                return 'Pear'
            elif bust_diff > hip_diff + 2:
                return 'Inverted Triangle'
            elif row['waist'] < (row['bust'] * 0.75) and row['waist'] < (row['hip'] * 0.75):
                return 'Hourglass'
            else:
                return 'Apple'
        
        self.df['body_shape'] = self.df.apply(determine_shape, axis=1)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.df.to_csv(f'synthetic_body_data_{timestamp}.csv', index=False)
        logger.info(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± synthetic_body_data_{timestamp}.csv Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§: {len(self.df)}")
        return self.df
    
    def data_analysis(self):
        """
        ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒØŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒØŒ Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ - Ù¾ÛŒØ´Ø±ÙØªÙ‡.
        """
        if self.df is None:
            self.generate_synthetic_data()
        
        logger.info("Ø´Ø±ÙˆØ¹ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
        
        # Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ
        print("\nğŸ“Š Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ:")
        print(self.df.describe())
        
        # Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ heatmap
        corr_matrix = self.df[['bust', 'hip', 'waist', 'height', 'weight_kg']].corr()
        print("\nğŸ”— Ù…Ø§ØªØ±ÛŒØ³ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ:")
        print(corr_matrix)
        
        # Heatmap Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ - fallback Ø§Ú¯Ø± sns Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ø¯
        plt.figure(figsize=(10, 8))
        if HAS_SNS:
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
        else:
            plt.imshow(corr_matrix, cmap='coolwarm', interpolation='none')
            plt.colorbar()
            plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=45)
            plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)
            for i in range(len(corr_matrix.columns)):
                for j in range(len(corr_matrix.columns)):
                    plt.text(j, i, f"{corr_matrix.iloc[i, j]:.2f}", ha='center', va='center')
        plt.title('Heatmap Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø¯Ù†')
        plt.tight_layout()
        plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # ØªÙˆØ²ÛŒØ¹ shape Ø¨Ø¯Ù†
        shape_dist = self.df['body_shape'].value_counts()
        print("\nğŸ“ˆ ØªÙˆØ²ÛŒØ¹ Ø´Ú©Ù„ Ø¨Ø¯Ù†:")
        print(shape_dist)
        
        # Ø¨Ø§Ú©Ø³â€ŒÙ¾Ù„Ø§Øª Ø¨Ø±Ø§ÛŒ ØªÙˆØ²ÛŒØ¹ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ shape
        plt.figure(figsize=(15, 10))
        self.df.boxplot(column=['bust', 'hip', 'waist'], by='body_shape', ax=plt.gca())
        plt.title('ØªÙˆØ²ÛŒØ¹ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ú©Ù„ Ø¨Ø¯Ù†')
        plt.suptitle('')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig('boxplot_by_shape.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        self.df['bust'].hist(bins=20, ax=axes[0], alpha=0.7, color='skyblue')
        axes[0].set_title('ØªÙˆØ²ÛŒØ¹ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø³ÛŒÙ†Ù‡ (Bust)')
        axes[0].set_xlabel('Ø§Ù†Ø¯Ø§Ø²Ù‡ (Ø§ÛŒÙ†Ú†)')
        
        self.df['hip'].hist(bins=20, ax=axes[1], alpha=0.7, color='lightgreen')
        axes[1].set_title('ØªÙˆØ²ÛŒØ¹ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ø§Ø³Ù† (Hip)')
        axes[1].set_xlabel('Ø§Ù†Ø¯Ø§Ø²Ù‡ (Ø§ÛŒÙ†Ú†)')
        
        shape_dist.plot(kind='pie', ax=axes[2], autopct='%1.1f%%')
        axes[2].set_title('ØªÙˆØ²ÛŒØ¹ Ø´Ú©Ù„ Ø¨Ø¯Ù†')
        
        plt.tight_layout()
        plt.savefig('advanced_analysis_plots.png', dpi=300, bbox_inches='tight')
        plt.show()
        logger.info("Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¯Ø± advanced_analysis_plots.png Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    
    def prepare_data_for_ml(self):
        """
        Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„: Ø§Ù†Ú©ÙˆØ¯ÛŒÙ†Ú¯ØŒ Ø§Ø³Ú©ÛŒÙ„ÛŒÙ†Ú¯ØŒ ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ - Ø¨Ø¯ÙˆÙ† sklearn.
        Ù‡Ø¯Ù: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ body_shape Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ.
        """
        features = ['bust', 'underbust', 'hip', 'waist', 'height', 'weight_kg', 'bicep', 'tricep', 'thigh', 'calf']
        X = self.df[features].values
        y = self.label_encoder.fit_transform(self.df['body_shape'].values)
        
        # Ø§Ø³Ú©ÛŒÙ„ÛŒÙ†Ú¯ Ø¯Ø³ØªÛŒ
        X_scaled = self.scaler.fit_transform(X)
        
        # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¯Ø³ØªÛŒ Ø¨Ø§ stratify
        X_train, X_test, y_train, y_test = manual_train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ØªÙ†Ø³ÙˆØ±
        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(self.device)
        y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(self.device)
        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(self.device)
        y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(self.device)
        
        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)
        
        self.train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        self.test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
        
        logger.info(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯. Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§: {self.label_encoder.classes_}")
        return self.train_loader, self.test_loader, X_test, y_test  # Ø¨Ø§Ø²Ú¯Ø´Øª y_test Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
    
    def define_model(self, input_size, num_classes):
        """
        ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„ Ø¹ØµØ¨ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ PyTorch - Ø¨Ø§ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯.
        """
        self.model = BodyShapeClassifier(input_size, num_classes).to(self.device)
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001, weight_decay=1e-5)
        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=20, gamma=0.1)
        logger.info("Ù…Ø¯Ù„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªØ¹Ø±ÛŒÙ Ø´Ø¯.")
    
    def train_model(self, epochs=100):
        """
        Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ Ù…Ù†Ø­Ù†ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„.
        """
        if self.model is None:
            input_size = len(['bust', 'underbust', 'hip', 'waist', 'height', 'weight_kg', 'bicep', 'tricep', 'thigh', 'calf'])
            num_classes = len(self.label_encoder.classes_)
            self.define_model(input_size, num_classes)
        
        logger.info(f"Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø±Ø§ÛŒ {epochs} ÑĞ¿Ğ¾Ñ…...")
        self.model.train()
        train_losses = []
        val_accuracies = []
        
        best_accuracy = 0
        for epoch in range(epochs):
            total_loss = 0
            for batch_x, batch_y in self.train_loader:
                self.optimizer.zero_grad()
                outputs = self.model(batch_x)
                loss = self.criterion(outputs, batch_y)
                loss.backward()
                self.optimizer.step()
                total_loss += loss.item()
            
            self.scheduler.step()
            avg_loss = total_loss / len(self.train_loader)
            train_losses.append(avg_loss)
            
            # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³Ø§Ø¯Ù‡ Ø¯Ø± Ù‡Ø± epoch
            val_acc = self._validate_model()
            val_accuracies.append(val_acc)
            
            if (epoch + 1) % 10 == 0:
                logger.info(f"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Val Acc: {val_acc:.4f}")
            
            if val_acc > best_accuracy:
                best_accuracy = val_acc
                torch.save(self.model.state_dict(), 'best_body_shape_model.pth')
        
        # Ù…Ù†Ø­Ù†ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
        plt.figure(figsize=(12, 4))
        plt.subplot(1, 2, 1)
        plt.plot(train_losses)
        plt.title('Ù…Ù†Ø­Ù†ÛŒ Loss Ø¢Ù…ÙˆØ²Ø´')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        
        plt.subplot(1, 2, 2)
        plt.plot(val_accuracies)
        plt.title('Ø¯Ù‚Øª Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.tight_layout()
        plt.savefig('learning_curves.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        torch.save(self.model.state_dict(), 'final_body_shape_model.pth')
        logger.info("Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± final_body_shape_model.pth Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯. Ø¨Ù‡ØªØ±ÛŒÙ† Ø¯Ù‚Øª: {:.2f}%".format(best_accuracy * 100))
    
    def _validate_model(self):
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³Ø±ÛŒØ¹ Ø¯Ø± Ø·ÙˆÙ„ Ø¢Ù…ÙˆØ²Ø´"""
        self.model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for batch_x, batch_y in self.test_loader:
                outputs = self.model(batch_x)
                _, predicted = torch.max(outputs, 1)
                total += batch_y.size(0)
                correct += (predicted == batch_y).sum().item()
        return correct / total
    
    def evaluate_model(self, X_test=None, y_test=None):
        """
        Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡: Ø¯Ù‚ØªØŒ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒØŒ Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ.
        """
        if X_test is None or y_test is None:
            features = ['bust', 'underbust', 'hip', 'waist', 'height', 'weight_kg', 'bicep', 'tricep', 'thigh', 'calf']
            X = self.scaler.transform(self.df[features].values)
            y = self.label_encoder.transform(self.df['body_shape'].values)
            _, X_test, _, y_test = manual_train_test_split(X, y, test_size=0.2)
        
        logger.info("Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„...")
        self.model.eval()
        y_pred = []
        y_true = []
        with torch.no_grad():
            test_tensor = torch.tensor(X_test, dtype=torch.float32).to(self.device)
            outputs = self.model(test_tensor)
            _, predicted = torch.max(outputs, 1)
            y_pred = predicted.cpu().numpy()
            y_true = y_test
        
        y_pred_labels = self.label_encoder.inverse_transform(y_pred)
        y_true_labels = self.label_encoder.inverse_transform(y_true)
        
        accuracy = np.mean(y_pred == y_true)
        print(f"\nğŸ¯ Ø¯Ù‚Øª Ù…Ø¯Ù„: {accuracy * 100:.2f}%")
        
        # Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ
        cm = manual_confusion_matrix(y_true, y_pred, labels=np.arange(len(self.label_encoder.classes_)))
        plt.figure(figsize=(8, 6))
        if HAS_SNS:
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.label_encoder.classes_, yticklabels=self.label_encoder.classes_)
        else:
            plt.imshow(cm, cmap='Blues', interpolation='none')
            plt.colorbar()
            plt.xticks(range(len(self.label_encoder.classes_)), self.label_encoder.classes_, rotation=45)
            plt.yticks(range(len(self.label_encoder.classes_)), self.label_encoder.classes_)
            for i in range(len(cm)):
                for j in range(len(cm)):
                    plt.text(j, i, str(cm[i, j]), ha='center', va='center')
        plt.title('Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ')
        plt.ylabel('ÙˆØ§Ù‚Ø¹ÛŒ')
        plt.xlabel('Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ')
        plt.tight_layout()
        plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
        report = manual_classification_report(y_true, y_pred, labels=np.arange(len(self.label_encoder.classes_)))
        print("\nğŸ“‹ Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:")
        for label_idx, metrics in report.items():
            label_name = self.label_encoder.inverse_transform([int(label_idx)])[0]
            print(f"{label_name}: precision={metrics['precision']:.2f}, recall={metrics['recall']:.2f}, f1-score={metrics['f1-score']:.2f}, support={metrics['support']}")
        
        logger.info(f"Ø¯Ù‚Øª: {accuracy * 100:.2f}%")
    
    def cross_validate(self, n_folds=5):
        """
        Ú©Ø±Ø§Ø³-ÙˆØ§Ù„ÛŒØ¯ÛŒØ´Ù† Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„.
        """
        logger.info(f"Ú©Ø±Ø§Ø³-ÙˆØ§Ù„ÛŒØ¯ÛŒØ´Ù† Ø¨Ø§ {n_folds} ÙÙˆÙ„Ø¯...")
        features = ['bust', 'underbust', 'hip', 'waist', 'height', 'weight_kg', 'bicep', 'tricep', 'thigh', 'calf']
        X = self.scaler.fit_transform(self.df[features].values)
        y = self.label_encoder.fit_transform(self.df['body_shape'].values)
        
        fold_accuracies = []
        fold_size = len(X) // n_folds
        
        for i in range(n_folds):
            val_start = i * fold_size
            val_end = (i + 1) * fold_size if i < n_folds - 1 else len(X)
            val_mask = np.arange(val_start, val_end)
            train_mask = np.concatenate((np.arange(0, val_start), np.arange(val_end, len(X))))
            
            X_train_fold, X_val_fold = X[train_mask], X[val_mask]
            y_train_fold, y_val_fold = y[train_mask], y[val_mask]
            
            # Ù…Ø¯Ù„ Ù…ÙˆÙ‚Øª
            model_fold = BodyShapeClassifier(len(features), len(self.label_encoder.classes_)).to(self.device)
            criterion_fold = nn.CrossEntropyLoss()
            optimizer_fold = optim.Adam(model_fold.parameters(), lr=0.001)
            
            # Ø¢Ù…ÙˆØ²Ø´ Ø³Ø±ÛŒØ¹ (10 epochs)
            model_fold.train()
            for _ in range(10):
                optimizer_fold.zero_grad()
                outputs = model_fold(torch.tensor(X_train_fold, dtype=torch.float32).to(self.device))
                loss = criterion_fold(outputs, torch.tensor(y_train_fold, dtype=torch.long).to(self.device))
                loss.backward()
                optimizer_fold.step()
            
            # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
            model_fold.eval()
            with torch.no_grad():
                outputs = model_fold(torch.tensor(X_val_fold, dtype=torch.float32).to(self.device))
                _, predicted = torch.max(outputs, 1)
                acc = (predicted.cpu().numpy() == y_val_fold).mean()
                fold_accuracies.append(acc)
        
        cv_accuracy = np.mean(fold_accuracies)
        print(f"\nğŸ”„ Ø¯Ù‚Øª Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú©Ø±Ø§Ø³-ÙˆØ§Ù„ÛŒØ¯ÛŒØ´Ù†: {cv_accuracy * 100:.2f}% (Â±{np.std(fold_accuracies) * 100:.2f}%)")
        logger.info(f"CV Accuracy: {cv_accuracy * 100:.2f}%")
    
    def predict_shape(self, measurements):
        """
        Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ú©Ù„ Ø¨Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯.
        measurements: dict Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        """
        if self.model is None:
            logger.warn("Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù†Ø¯ÛŒØ¯Ù‡ Ø§Ø³Øª.")
            return None
        
        features = ['bust', 'underbust', 'hip', 'waist', 'height', 'weight_kg', 'bicep', 'tricep', 'thigh', 'calf']
        input_data = np.array([measurements.get(f, 0) for f in features]).reshape(1, -1)
        input_scaled = self.scaler.transform(input_data)
        input_tensor = torch.tensor(input_scaled, dtype=torch.float32).to(self.device)
        
        self.model.eval()
        with torch.no_grad():
            output = self.model(input_tensor)
            _, predicted = torch.max(output, 1)
            shape_idx = predicted.item()
            predicted_shape = self.label_encoder.inverse_transform([shape_idx])[0]
        
        return predicted_shape
    
    def interactive_predict(self):
        """
        Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±.
        """
        print("\nğŸ–¥ï¸  Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ø´Ú©Ù„ Ø¨Ø¯Ù†:")
        measurements = {}
        features = ['bust', 'underbust', 'hip', 'waist', 'height', 'weight_kg', 'bicep', 'tricep', 'thigh', 'calf']
        for f in features:
            try:
                val = float(input(f"ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ {f} (Ø§ÛŒÙ†Ú†/Ú©ÛŒÙ„Ùˆ): "))
                measurements[f] = val
            except ValueError:
                logger.error(f"Ù…Ù‚Ø¯Ø§Ø± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ {f}")
                return None
        
        predicted = self.predict_shape(measurements)
        if predicted:
            print(f"ğŸ”® Ø´Ú©Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡: {predicted}")
        return predicted

def main():
    analyzer = BodyDataAnalyzer(num_samples=2000)  # Ø§ÙØ²Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
    
    # 1. ØªÙˆÙ„ÛŒØ¯ Ùˆ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡
    df = analyzer.generate_synthetic_data()
    analyzer.data_analysis()
    
    # 2. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ML
    train_loader, test_loader, X_test, y_test = analyzer.prepare_data_for_ml()
    
    # 3. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    analyzer.train_model(epochs=100)  # epochs Ø¨ÛŒØ´ØªØ±
    
    # 4. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
    analyzer.evaluate_model(X_test, y_test)
    
    # 5. Ú©Ø±Ø§Ø³-ÙˆØ§Ù„ÛŒØ¯ÛŒØ´Ù†
    analyzer.cross_validate(n_folds=5)
    
    # 6. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø«Ø§Ù„ (Ø¨Ø± Ø§Ø³Ø§Ø³ Dart)
    example_measurements = {
        'bust': 36.0, 'underbust': 32.0, 'hip': 38.5, 'waist': 28.0,
        'height': 65.0, 'weight_kg': 60.0, 'bicep': 13.0, 'tricep': 12.5,
        'thigh': 22.0, 'calf': 14.0
    }
    predicted = analyzer.predict_shape(example_measurements)
    print(f"\nğŸ”® Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø´Ú©Ù„ Ø¨Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„: {predicted}")
    
    # 7. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
    if input("Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ¹Ø§Ù…Ù„ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯ØŸ (y/n): ").lower() == 'y':
        analyzer.interactive_predict()
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø®Ù„Ø§ØµÙ‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡
    summary = {
        'num_samples': analyzer.num_samples,
        'classes': list(analyzer.label_encoder.classes_),
        'timestamp': datetime.now().isoformat(),
        'model_path': 'final_body_shape_model.pth',
        'data_path': 'synthetic_body_data_*.csv'
    }
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    with open(f'ml_summary_{timestamp}.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=4, ensure_ascii=False)
    logger.info(f"Ø®Ù„Ø§ØµÙ‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¯Ø± ml_summary_{timestamp}.json Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

if __name__ == "__main__":
    main()
